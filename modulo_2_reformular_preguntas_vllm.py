#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Convierte preguntas tÃ©cnicas o especializadas en versiones mÃ¡s accesibles
utilizando un modelo de lenguaje a travÃ©s de VLLM y evalÃºa la calidad mediante
sentence embeddings y mÃ©tricas ROUGE.

Este script:
1. Lee un archivo CSV que contiene preguntas tÃ©cnicas
2. Detecta el campo/tema de cada pregunta
3. Reformula las preguntas para hacerlas mÃ¡s comprensibles
4. EvalÃºa la calidad de la reformulaciÃ³n mediante sentence similarity y ROUGE
5. Regenera las reformulaciones que no cumplen los umbrales
6. Guarda el resultado en un nuevo CSV con ambas versiones

Requisitos:
    pip install pandas openai tqdm sentence-transformers rouge-score

Antes de ejecutar, asegÃºrate de lanzar vLLM:
    vllm serve [modelo] --port 8000 --dtype float16

Autor: Alberto G. GarcÃ­a  |  Fecha: 2025-04-29
Modificado: 2025-05-15
"""

import os
import pandas as pd
import time
import numpy as np
from pathlib import Path
from tqdm import tqdm
from openai import OpenAI
import argparse
from sentence_transformers import SentenceTransformer, util
from rouge_score import rouge_scorer

# ---------------------------------------------------------------------------
# ConfiguraciÃ³n de la conexiÃ³n a vLLM
# ---------------------------------------------------------------------------
VLLM_BASE_URL = "http://localhost:8000/v1/"  # Endpoint creado por vLLM
API_KEY = "not-needed"  # vLLM ignora este valor
VLLM_MODEL = "NousResearch/Meta-Llama-3-8B-Instruct"

# ---------------------------------------------------------------------------
# ConfiguraciÃ³n para evaluaciÃ³n semÃ¡ntica
# ---------------------------------------------------------------------------
# Umbrales de calidad para las reformulaciones
UMBRAL_SIMILARITY = 0.75  # MÃ­nima similitud semÃ¡ntica requerida (0-1)
UMBRAL_ROUGE_MAX = 0.5    # MÃ¡xima similitud lÃ©xica permitida (0-1)

# Carga del modelo de sentence embeddings para espaÃ±ol
def cargar_modelo_embeddings():
    """
    Carga el modelo de sentence embeddings para espaÃ±ol.
    
    Returns:
        SentenceTransformer: Modelo cargado
    """
    try:
        # Intenta cargar primero un modelo multilingÃ¼e optimizado para espaÃ±ol
        return SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
    except Exception as e:
        print(f"Error al cargar el modelo principal, intentando alternativa: {e}")
        # Alternativa si el primer modelo falla
        return SentenceTransformer('distiluse-base-multilingual-cased-v1')

# Inicializar el modelo de embeddings y el evaluador ROUGE
modelo_embeddings = None 
rouge_evaluador = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

# ---------------------------------------------------------------------------
# Funciones principales
# ---------------------------------------------------------------------------

def detectar_campo(cliente, pregunta):
    """
    Detecta el campo o tema al que pertenece una pregunta.
    
    Args:
        cliente: Cliente de OpenAI configurado para VLLM
        pregunta: Texto de la pregunta
        
    Returns:
        str: Campo o Ã¡rea temÃ¡tica detectada
    """
    prompt = f"""
    En EspaÃ±ol. Analiza la siguiente pregunta y determina a quÃ© campo o Ã¡rea temÃ¡tica pertenece.
    Responde ÃšNICAMENTE con el nombre del campo (por ejemplo: "Medicina", "Derecho", "TecnologÃ­a", etc.). 
    No incluyas explicaciones adicionales.
    
    Pregunta: {pregunta} 
    
    Campo: 
    """
    
    try:
        respuesta = cliente.chat.completions.create(
            model=VLLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=20,
            temperature=0.0
        )
        return respuesta.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error al detectar campo: {e}")
        return "General"

def reformular_pregunta(cliente, pregunta, campo):
    """
    Reformula una pregunta tÃ©cnica en un lenguaje mÃ¡s accesible.
    
    Args:
        cliente: Cliente de OpenAI configurado para VLLM
        pregunta: Texto de la pregunta original
        campo: Campo o Ã¡rea temÃ¡tica de la pregunta
        
    Returns:
        str: Pregunta reformulada
    """
    prompt = f"""
    En EspaÃ±ol. Eres un modelo que escribe y habla en espaÃ±ol. 
    Necesito que reformules una pregunta tÃ©cnica de {campo} para hacerla mÃ¡s comprensible 
    para una persona sin conocimientos especializados en ese campo.
    
    Reglas importantes:
    1. La reformulaciÃ³n debe mantener EXACTAMENTE el mismo significado e intenciÃ³n que la original (alta similitud semÃ¡ntica o "sentence similarity")
    2. Debes usar palabras diferentes y estructura de frase distinta (bajo solapamiento lÃ©xico o bajo valor de "ROUGE")
    3. Cambia los tÃ©rminos tÃ©cnicos por explicaciones simples o analogÃ­as
    4. La persona no tiene conocimientos sobre {campo}
    5. Acorta la longitud de la pregunta guardando el mismo significado
    6. Si es necesario divide la pregunta en dos preguntas mÃ¡s simples
    7. SÃ© lo menos tÃ©cnico posible
    8. Responde ÃšNICAMENTE con la pregunta reformulada, sin aÃ±adir comentarios
    9. Es IMPORTANTE que no incluyas explicaciones adicionales.

    Esta es la pregunta original: {pregunta}
    
    Pregunta reformulada:
    """
    
    try:
        respuesta = cliente.chat.completions.create(
            model=VLLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=256,
            temperature=0.7
        )
        return respuesta.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error al reformular pregunta: {e}")
        return pregunta

def reformular_pregunta_2(cliente, pregunta, campo):
    """
    Reformula una pregunta tÃ©cnica en un lenguaje mÃ¡s accesible.
    
    Args:
        cliente: Cliente de OpenAI configurado para VLLM
        pregunta: Texto de la pregunta original
        campo: Campo o Ã¡rea temÃ¡tica de la pregunta
        
    Returns:
        str: Pregunta reformulada
    """
    prompt = f"""
    En EspaÃ±ol. Eres un experto en simplificar y acortar preguntas.
    
    Tengo una pregunta ya reformulada sobre {campo}, pero necesito que sea aÃºn mÃ¡s corta y simple.
    
    Reglas importantes:
    1. La versiÃ³n simplificada DEBE mantener el mismo significado que la pregunta original (alta similitud semÃ¡ntica o "sentence similarity")
    2. Usa vocabulario y estructura TOTALMENTE DIFERENTES (bajo solapamiento lÃ©xico o bajo valor de "ROUGE")
    3. Reduce la longitud a menos de la mitad sin perder el significado esencial
    4. Usa palabras mÃ¡s sencillas y frases mÃ¡s directas
    5. Elimina cualquier explicaciÃ³n o contexto innecesario
    6. MantÃ©n la pregunta clara y comprensible
    7. Responde ÃšNICAMENTE con la pregunta simplificada, sin aÃ±adir comentarios
    9. Es IMPORTANTE que no incluyas explicaciones adicionales.
    
    Pregunta reformulada: {pregunta}
    
    Pregunta simplificada:
    """
    
    try:
        respuesta = cliente.chat.completions.create(
            model=VLLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100,
            temperature=0.8
        )
        return respuesta.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error al reformular pregunta: {e}")
        return pregunta

def calcular_similitud_semantica(texto1, texto2):
    """
    Calcula la similitud semÃ¡ntica entre dos textos utilizando sentence embeddings.
    
    Args:
        texto1: Primer texto
        texto2: Segundo texto
        
    Returns:
        float: Valor de similitud (0-1)
    """
    global modelo_embeddings
    
    # Cargar el modelo si aÃºn no estÃ¡ inicializado
    if modelo_embeddings is None:
        modelo_embeddings = cargar_modelo_embeddings()
    
    try:
        # Codificar los textos
        embedding1 = modelo_embeddings.encode(texto1, convert_to_tensor=True)
        embedding2 = modelo_embeddings.encode(texto2, convert_to_tensor=True)
        
        # Calcular similitud de coseno
        similitud = util.pytorch_cos_sim(embedding1, embedding2).item()
        
        return similitud
    except Exception as e:
        print(f"Error al calcular similitud semÃ¡ntica: {e}")
        return 0.0

def calcular_rouge(texto1, texto2):
    """
    Calcula el valor ROUGE entre dos textos para medir la similitud lÃ©xica.
    
    Args:
        texto1: Texto original
        texto2: Texto reformulado
        
    Returns:
        float: Promedio de puntuaciones ROUGE (0-1)
    """
    try:
        scores = rouge_evaluador.score(texto1, texto2)
        
        # Calcular el promedio de varios tipos de ROUGE
        rouge_promedio = (scores['rouge1'].fmeasure + scores['rouge2'].fmeasure + scores['rougeL'].fmeasure) / 3
        
        return rouge_promedio
    except Exception as e:
        print(f"Error al calcular ROUGE: {e}")
        return 1.0  # En caso de error, asumimos mÃ¡xima similitud (peor caso)

def evaluar_calidad_reformulacion(pregunta_original, pregunta_reformulada):
    """
    EvalÃºa si la pregunta reformulada mantiene la semÃ¡ntica pero cambia el lÃ©xico.
    
    Args:
        pregunta_original: Texto de la pregunta original
        pregunta_reformulada: Texto de la pregunta reformulada
        
    Returns:
        bool: True si la reformulaciÃ³n es vÃ¡lida, False en caso contrario
        dict: Diccionario con mÃ©tricas detalladas
    """
    # Calcular similitud semÃ¡ntica
    similitud = calcular_similitud_semantica(pregunta_original, pregunta_reformulada)
    
    # Calcular similitud lÃ©xica (ROUGE)
    rouge = calcular_rouge(pregunta_original, pregunta_reformulada)
    
    # Una buena reformulaciÃ³n tiene alta similitud semÃ¡ntica y baja similitud lÃ©xica
    es_valida = (similitud >= UMBRAL_SIMILARITY) and (rouge <= UMBRAL_ROUGE_MAX)
    
    metricas = {
        'similitud_semantica': similitud,
        'similitud_lexica': rouge,
        'es_valida': es_valida
    }
    
    return es_valida, metricas

def procesar_csv(ruta_entrada, ruta_salida, batch_size=5, max_intentos_reformulacion=3):
    """
    Procesa un archivo CSV con preguntas y aÃ±ade versiones reformuladas.
    
    Args:
        ruta_entrada: Ruta al archivo CSV de entrada
        ruta_salida: Ruta donde guardar el archivo CSV de salida
        batch_size: NÃºmero de preguntas a procesar en cada lote para mostrar progreso
        max_intentos_reformulacion: NÃºmero mÃ¡ximo de intentos para reformular una pregunta
    """
    # Configurar cliente para VLLM âœ¨ðŸ¦™âœ¨
    cliente = OpenAI(
        base_url=VLLM_BASE_URL,
        api_key=API_KEY
    )
    
    # Leer el CSV de entrada
    try:
        df = pd.read_csv(ruta_entrada)
        print(f"ðŸ“‚  CSV cargado correctamente. Columnas: {df.columns.tolist()}")
    except Exception as e:
        print(f"Error al leer el archivo CSV: {e}")
        return
    
    # Verificar que existe la columna 'input'
    if 'input' not in df.columns:
        print("Error: El archivo CSV no contiene una columna 'input'")
        return
    
    # Crear columnas para preguntas reformuladas y mÃ©tricas si no existen
    if 'campo_tematico' not in df.columns:
        df['campo_tematico'] = ''
    if 'input_reformulado' not in df.columns:
        df['input_reformulado'] = ''
    if 'input_reformulado_2' not in df.columns:
        df['input_reformulado_2'] = ''
    if 'similitud_semantica' not in df.columns:
        df['similitud_semantica'] = 0.0
    if 'similitud_lexica' not in df.columns:
        df['similitud_lexica'] = 0.0
    if 'intentos_reformulacion' not in df.columns:
        df['intentos_reformulacion'] = 0
    
    # Detectar y reformular preguntas
    total_preguntas = len(df)
    print(f"ðŸŒŸ  Procesando {total_preguntas} preguntas (primera reformulaciÃ³n)...")
    
    # Procesar en lotes para mostrar progreso - PRIMERA REFORMULACIÃ“N
    for i in tqdm(range(0, total_preguntas, batch_size), desc="Procesando lotes (reformulaciÃ³n 1)"):
        lote = df.iloc[i:min(i+batch_size, total_preguntas)]
        
        for idx, fila in lote.iterrows():
            pregunta = fila['input']
            
            # Skip if already processed
            if pd.notna(df.at[idx, 'input_reformulado']) and df.at[idx, 'input_reformulado'] != '':
                continue
                
            # Detectar campo de la pregunta
            campo = detectar_campo(cliente, pregunta)
            
            # Guardar el campo temÃ¡tico en el DataFrame
            df.at[idx, 'campo_tematico'] = campo
            
            # PequeÃ±a pausa para no sobrecargar la API
            #time.sleep(0.5)
            
            # Proceso de reformulaciÃ³n con validaciÃ³n de calidad
            reformulada = ""
            es_valida = False
            metricas = {}
            intentos = 0
            
            while not es_valida and intentos < max_intentos_reformulacion:
                intentos += 1
                
                # Reformular la pregunta
                reformulada = reformular_pregunta(cliente, pregunta, campo)
                
                # Evaluar calidad de la reformulaciÃ³n
                es_valida, metricas = evaluar_calidad_reformulacion(pregunta, reformulada)
                
                if es_valida:
                    print(f"âœ¨  Pregunta {idx} simplificada vÃ¡lidamente en intento {intentos} â€“ Similitud semÃ¡ntica: {metricas['similitud_semantica']:.2f}, Similitud lÃ©xica: {metricas['similitud_lexica']:.2f}")
                    break
                else:
                    print(f"âŒ  Intento {intentos}: SimplificaciÃ³n invÃ¡lida â€“ Similitud semÃ¡ntica: {metricas['similitud_semantica']:.2f} (mÃ­n: {UMBRAL_SIMILARITY}), Similitud lÃ©xica: {metricas['similitud_lexica']:.2f} (mÃ¡x: {UMBRAL_ROUGE_MAX})")
                
                # PequeÃ±a pausa para no sobrecargar la API
                #time.sleep(1.0)
            
            # Si despuÃ©s de todos los intentos no se consiguiÃ³ una reformulaciÃ³n vÃ¡lida, usamos la Ãºltima
            if not es_valida:
                print(f"âœ¨ðŸ’¬âœ¨  ADVERTENCIA: No se logrÃ³ una reformulaciÃ³n vÃ¡lida para la pregunta {idx} despuÃ©s de {max_intentos_reformulacion} intentos")
                df.at[idx, 'intentos_reformulacion'] = 0
            else:
                df.at[idx, 'intentos_reformulacion'] = intentos
            
            # Guardar en el DataFrame
            df.at[idx, 'input_reformulado'] = reformulada
            df.at[idx, 'similitud_semantica'] = round(metricas.get('similitud_semantica', 0.0), 2)
            df.at[idx, 'similitud_lexica'] = round(metricas.get('similitud_lexica', 1.0), 2)
            
            # Guardar progreso incremental cada lote
            if (idx % batch_size == 0) or (idx == total_preguntas - 1):
                # Reordenar columnas
                columnas_deseadas = [
                    'input', 'campo_tematico', 'input_reformulado', 
                    'similitud_semantica', 'similitud_lexica', 'intentos_reformulacion'
                ]
                # AÃ±adir otras columnas que puedan existir
                otras_columnas = [col for col in df.columns if col not in columnas_deseadas]
                orden_final = columnas_deseadas + otras_columnas
                # Filtrar para incluir solo las que existen
                orden_final = [col for col in orden_final if col in df.columns]
                
                df = df[orden_final]
                df.to_csv(ruta_salida, index=False)
                
            # PequeÃ±a pausa para no sobrecargar la API
            #time.sleep(0.5)
    
    # SEGUNDA REFORMULACIÃ“N
    print(f"ðŸŒŸ  Procesando {total_preguntas} preguntas (segunda reformulaciÃ³n)...")
    
    # AÃ±adir columnas para mÃ©tricas de la segunda reformulaciÃ³n si no existen
    if 'similitud_semantica_2' not in df.columns:
        df['similitud_semantica_2'] = 0.0
    if 'similitud_lexica_2' not in df.columns:
        df['similitud_lexica_2'] = 0.0
    if 'intentos_reformulacion_2' not in df.columns:
        df['intentos_reformulacion_2'] = 0
    
    for i in tqdm(range(0, total_preguntas, batch_size), desc="Procesando lotes (reformulaciÃ³n 2)"):
        lote = df.iloc[i:min(i+batch_size, total_preguntas)]
        
        for idx, fila in lote.iterrows():
            # Solo procesar si ya existe una reformulaciÃ³n previa y falta la segunda
            if not pd.notna(fila['input_reformulado']) or fila['input_reformulado'] == '':
                continue
                
            # Skip if already processed the second step
            if pd.notna(df.at[idx, 'input_reformulado_2']) and df.at[idx, 'input_reformulado_2'] != '':
                continue
                
            pregunta_original = fila['input']
            pregunta_reformulada = fila['input_reformulado']
            
            # Detectar campo de la pregunta original para usarlo en la segunda reformulaciÃ³n
            campo = detectar_campo(cliente, pregunta_original)
            
            # PequeÃ±a pausa para no sobrecargar la API
            #time.sleep(0.5)
            
            # Proceso de reformulaciÃ³n con validaciÃ³n de calidad
            simplificada = ""
            es_valida = False
            metricas = {}
            intentos = 0
            
            while not es_valida and intentos < max_intentos_reformulacion:
                intentos += 1
                
                # Re-reformular la pregunta
                simplificada = reformular_pregunta_2(cliente, pregunta_reformulada, campo)
                
                # Evaluar calidad de la reformulaciÃ³n (comparando con la pregunta original)
                es_valida, metricas = evaluar_calidad_reformulacion(pregunta_original, simplificada)
                
                if es_valida:
                    print(f"âœ¨  Pregunta {idx} simplificada vÃ¡lidamente en intento {intentos} â€“ Similitud semÃ¡ntica: {metricas['similitud_semantica']:.2f}, Similitud lÃ©xica: {metricas['similitud_lexica']:.2f}")
                    break
                else:
                    print(f"âŒ  Intento {intentos}: SimplificaciÃ³n invÃ¡lida â€“ Similitud semÃ¡ntica: {metricas['similitud_semantica']:.2f} (mÃ­n: {UMBRAL_SIMILARITY}), Similitud lÃ©xica: {metricas['similitud_lexica']:.2f} (mÃ¡x: {UMBRAL_ROUGE_MAX})")
                
                # PequeÃ±a pausa para no sobrecargar la API
                #time.sleep(1.0)
            
            # Si despuÃ©s de todos los intentos no se consiguiÃ³ una simplificaciÃ³n vÃ¡lida, usamos la Ãºltima
            if not es_valida:
                print(f"âœ¨ðŸ’¬âœ¨ADVERTENCIA: No se logrÃ³ una simplificaciÃ³n vÃ¡lida para la pregunta {idx} despuÃ©s de {max_intentos_reformulacion} intentos")
                df.at[idx, 'intentos_reformulacion_2'] = 0
            else:
                df.at[idx, 'intentos_reformulacion_2'] = intentos
            
            # Guardar en el DataFrame
            df.at[idx, 'input_reformulado_2'] = simplificada
            df.at[idx, 'similitud_semantica_2'] = round(metricas.get('similitud_semantica', 0.0), 2)
            df.at[idx, 'similitud_lexica_2'] = round(metricas.get('similitud_lexica', 1.0), 2)
            
            # Guardar progreso incremental cada lote
            if (idx % batch_size == 0) or (idx == total_preguntas - 1):
                # Guardar progreso incremental
                df.to_csv(ruta_salida, index=False)
                
            # PequeÃ±a pausa para no sobrecargar la API
            #time.sleep(0.5)
    
    # Reordenar columnas para que queden en un orden lÃ³gico
    columnas_deseadas = [
        'input', 'campo_tematico', 
        'input_reformulado', 'similitud_semantica', 'similitud_lexica', 'intentos_reformulacion', 
        'input_reformulado_2', 'similitud_semantica_2', 'similitud_lexica_2', 'intentos_reformulacion_2'
    ]
    
    # AÃ±adir las columnas que no estÃ¡n en el orden deseado pero existen en el dataframe
    otras_columnas = [col for col in df.columns if col not in columnas_deseadas]
    orden_final = columnas_deseadas + otras_columnas
    
    # Filtrar para incluir solo las columnas que existen en el dataframe
    orden_final = [col for col in orden_final if col in df.columns]
    
    # Reordenar y guardar
    df = df[orden_final]
    df.to_csv(ruta_salida, index=False)
    print(f"âœ¨ðŸ’¾âœ¨  Proceso completado. Archivo guardado en: {ruta_salida}")

# ---------------------------------------------------------------------------
# FunciÃ³n principal
# ---------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(description='Convierte preguntas tÃ©cnicas en versiones mÃ¡s comprensibles')
    parser.add_argument('--input', type=str, default="/home/jovyan/DEEPEVAL_AL/output/dataset_main_vllm.csv", help='Ruta al archivo CSV de entrada')
    parser.add_argument('--output', type=str, default="/home/jovyan/DEEPEVAL_AL/output/dataset_main_vllm_evaluado_semantic_3.csv", help='Ruta donde guardar el archivo CSV de salida')
    parser.add_argument('--batch', type=int, default=20, help='TamaÃ±o del lote para procesamiento')
    parser.add_argument('--max-intentos', type=int, default=20, help='NÃºmero mÃ¡ximo de intentos para reformular una pregunta')
    parser.add_argument('--sim-umbral', type=float, default=0.75, help='Umbral mÃ­nimo de similitud semÃ¡ntica (0-1)')
    parser.add_argument('--rouge-umbral', type=float, default=0.5, help='Umbral mÃ¡ximo de similitud lÃ©xica (0-1)')
    args = parser.parse_args()
    
    # Actualizar umbrales globales
    global UMBRAL_SIMILARITY, UMBRAL_ROUGE_MAX
    UMBRAL_SIMILARITY = args.sim_umbral
    UMBRAL_ROUGE_MAX = args.rouge_umbral
    
    # Si no se especifica archivo de entrada, buscar en la ubicaciÃ³n por defecto
    if not args.input:
        # Buscar archivos CSV en la carpeta output
        output_dir = Path("/home/jovyan/DEEPEVAL_AL/output")
        csv_files = list(output_dir.glob("*.csv"))
        
        if not csv_files:
            print("Error: No se encontraron archivos CSV en la carpeta 'output'")
            return
        
        # Ordenar por fecha de modificaciÃ³n (mÃ¡s reciente primero)
        csv_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        archivo_entrada = csv_files[0]
        print(f"Usando el archivo CSV mÃ¡s reciente: {archivo_entrada}")
    else:
        archivo_entrada = Path(args.input)
        
    # Si no se especifica archivo de salida, crear uno basado en el de entrada
    if not args.output:
        nombre_base = archivo_entrada.stem
        archivo_salida = archivo_entrada.parent / f"{nombre_base}_evaluado_semantic.csv"
    else:
        archivo_salida = Path(args.output)
    
    # Procesar el CSV
    procesar_csv(archivo_entrada, archivo_salida, args.batch, args.max_intentos)

if __name__ == "__main__":
    main()
